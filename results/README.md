\## Results



The model was evaluated using:

âœ… Evaluation Results

Accuracy : 0.8
Precision: 0.8
Recall   : 0.8
F1-Score : 0.8


<img width="439" height="393" alt="image" src="https://github.com/user-attachments/assets/6cd37804-f2b7-45ba-80dc-bd3a197871ac" />



Sample performance:

\- Accuracy: ~80%

\- Balanced precision and recall



Classification Report:

              precision    recall  f1-score   support

        Real       0.80      0.80      0.80         5
        Fake       0.80      0.80      0.80         5

    accuracy                           0.80        10
   macro avg       0.80      0.80      0.80        10
weighted avg       0.80      0.80      0.80        10



Detailed evaluation was performed in Jupyter/Colab notebooks.



